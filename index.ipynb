{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "boston = load_boston()\n",
    "y = pd.DataFrame(boston.target,columns = [\"target\"])\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "all_data = pd.concat([y,df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = preprocessing.scale(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_scaled, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176324491383005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "baseline = np.mean(cross_val_score(regression, df, y, scoring=\"r2\", cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))\n",
    "interactions = []\n",
    "data = df.copy()\n",
    "for i in combinations:\n",
    "    data['interaction'] = data[i[0]] * data[i[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if score > baseline:\n",
    "        interactions.append((i[0], i[1], round(score,3)))\n",
    "print(\"Top 7 interactions: %s\" %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_inter = df.copy()\n",
    "df_inter['RM_LSTAT'] = df['RM'] * df['LSTAT']\n",
    "df_inter['RM_TAX'] = df['RM'] * df['TAX']\n",
    "df_inter['RM_RAD'] = df['RM'] * df['RAD']\n",
    "df_inter['RM_PTRATIO'] = df['RM'] * df['PTRATIO']\n",
    "df_inter['RM_INDUS'] = df['RM'] * df['INDUS']\n",
    "df_inter['RM_NOX'] = df['RM'] * df['NOX']\n",
    "df_inter['RM_AGE'] = df['RM'] * df['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>RM_INDUS</th>\n",
       "      <th>RM_NOX</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  RM_INDUS    RM_NOX    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in df.columns:\n",
    "    for degree in [2,3,4]:\n",
    "        data = df.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X = poly.fit_transform(df[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X)], axis = 1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score,3)))\n",
    "print(\"Top 10 polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "CHAS       0.718\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.719\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RM and LSTAT have highest r squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in [\"RM\", \"LSTAT\"]:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X = poly.fit_transform(df[[col]])\n",
    "    colnames= [col, col+\"_\"+\"2\", col+\"_\"+\"3\", col+\"_\"+\"4\"]\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1),pd.DataFrame(X, columns=colnames)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>RM_NOX</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>1.156834</td>\n",
       "      <td>-1.244247</td>\n",
       "      <td>1.338266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>0.242497</td>\n",
       "      <td>-0.119415</td>\n",
       "      <td>0.058805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>1.645354</td>\n",
       "      <td>2.110519</td>\n",
       "      <td>2.707191</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>1.461022</td>\n",
       "      <td>-1.765977</td>\n",
       "      <td>2.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>1.032871</td>\n",
       "      <td>1.049709</td>\n",
       "      <td>1.066822</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>1.853728</td>\n",
       "      <td>-2.523882</td>\n",
       "      <td>3.436308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>1.509401</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>2.278290</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>1.053705</td>\n",
       "      <td>-1.081630</td>\n",
       "      <td>1.110295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO    ...       RM_NOX    RM_AGE        RM  \\\n",
       "0 -0.982843 -0.666608 -1.459000    ...    -0.059659 -0.049646  0.413672   \n",
       "1 -0.867883 -0.987329 -0.303094    ...    -0.143814  0.071331  0.194274   \n",
       "2 -0.867883 -0.987329 -0.303094    ...    -0.949544 -0.340960  1.282714   \n",
       "3 -0.752922 -1.106115  0.113032    ...    -0.848901 -0.823092  1.016303   \n",
       "4 -0.752922 -1.106115  0.113032    ...    -1.026210 -0.628023  1.228577   \n",
       "\n",
       "       RM_2      RM_3      RM_4     LSTAT   LSTAT_2   LSTAT_3   LSTAT_4  \n",
       "0  0.171124  0.070789  0.029284 -1.075562  1.156834 -1.244247  1.338266  \n",
       "1  0.037743  0.007332  0.001425 -0.492439  0.242497 -0.119415  0.058805  \n",
       "2  1.645354  2.110519  2.707191 -1.208727  1.461022 -1.765977  2.134585  \n",
       "3  1.032871  1.049709  1.066822 -1.361517  1.853728 -2.523882  3.436308  \n",
       "4  1.509401  1.854414  2.278290 -1.026501  1.053705 -1.081630  1.110295  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061116489237063"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "regression = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "full_r2 = np.mean(cross_val_score(regression, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "full_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Information-criterion for model selection')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn import datasets\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "EPSILON = 1e-4\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_ + EPSILON\n",
    "    alphas_ = model.alphas_ + EPSILON\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s criterion' % name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
    "                label='alpha: %s estimate' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7532830453044879\n",
      "Testing r^2: 0.6838681538775355\n",
      "Training MSE: 21.53767761812234\n",
      "Testing MSE: 23.932008664495555\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8460939018149843\n",
      "Testing r^2: 0.7956012922049855\n",
      "Training MSE: 14.301385928866528\n",
      "Testing MSE: 10.488693901464627\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8553642921489537\n",
      "Testing r^2: 0.7604705808800662\n",
      "Training MSE: 11.721571121765974\n",
      "Testing MSE: 22.48335964646014\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
